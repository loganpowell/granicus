## April 22, 2020

1. graphql data modelling for storing granicus data
2. fetch granicus historical data and store it to grapqhl API

```diff
# a credo via discovery
  
  ALL SORTS OF PROGRESS
  RESULT FROM SOME LEAP
  
  ADVENTURE IN ITS BULK
  AWAIT STEPS YET TAKEN
  
  WE HESITATE FROM FEAR
  
  IT TAKES SOME COURAGE
  TO PLAY WITH UNKNOWNS
  CHANCING TO A FAILURE
  CHANCING TO A VICTORY
  
  IT'S MORE EASILY DONE
  BY MANNER OF CHILDREN
  NOT EMBARRASED AT ALL
  TO TAKE BABIES' STEPS 
  
+ SO TAKE BABIES' STEPS
  ONTO THE UNKNOWN PATH
  EACH STEP A DISCOVERY
+ A TINY DREAM COME TRUE
  
# (TDD as a design tool)
```

## Desired Data Ontology

- topic
  - subscriber
  - bulletin detail
    - campaign (UTM)
    - link
      - unsubscribe

## Granicus API Ontology

- day
  - bulletin detail
  - link
    - unsubscribe
    - campaign (UTM)
- topic

## AWS Appsync Graphql Directives Used

- `@model`
- `@connection`
- `@key`

## Data Modelling

```sh

type Topic {

}

type BulletinDetail @model {
  id: ID!
  created_at: String
  subject: String
  to_text: String
  delivery_status_name: String
  addresses_count: Int
  success_count: Int
  failed_count: Int
  percent_success: Float
  immediate_email_recipients: Int 
  emails_delivered: Int
  emails_failed: Int
  percent_emails_delivered: Float 
  opens_count: Int
  percent_opened: Float
  nonunique_opens_count: Int
  links_count: Int
  click_rate: Float
  clicks_count: Int
  nonunique_clicks_count: Int 
  sender_email: String
  digest_email_recipients: Int 
  wireless_recipients: Int
  wireless_delivered: Int
  wireless_failed_count: Int
  bulletin_visibility?: String
  publish_to_facebook: String
  facebook_name: String
  publish_to_twitter: String
  twitter_account: String
  publish_to_rss?: String
  wireless_unique_clicks: Int 
  wireless_nonunique_clicks: Int
  facebook_nonunique_clicks: Int
  twitter_nonunique_clicks: Int
  # CUSTOM FIELDS ////////////////////////
  # calculated during storage function
  unique_unsubscribe_click_count: Int 
  total_unsubscribe_click_count: Int 
  # fetched during storage
  links: [Link] 
  # allow BulletinDetails to be queried by CampaignTag and vice versa
  # adds a GSI (global secondary index) to DynamoDB
  campaign: CampaignTag @connection(name: "BulletinCampaign", sortField: "created_at")
}

type Link {
  link_url: String,
  subject: String,
  sent_at: String,
  sender_email: String
  unique_click_count: Int
  total_click_count: Int
}

type CampaignTag {
  bulletins: [BulletinDetail] @connection(name: "BulletinCampaign", sortField: "created_at")
  created_at: String
}

```

## One time batch Function

`function_batch`(update?):
01. `forEach`: each day since inception
  01. Granicus API for the Day (`start_date` + `end_date` = same date (YYYY-MM-DD))
  02. fetch: the Bulletins sent that day
  03. for each bulletin detail (by `id`):
      1. fetch: links for bulletin 
      2. store to `links`
      3. use the `unsubscribe` link object to calculate `unique/total_unsubscribe_click_count`s
      4. return: parse the campaign `utm` tags out of the links
  04. if (update?) && || `get` by `id` == true (exists in DB) :
      0. false: return: `create` `campaign` -> `create` `BulletinDetail`
      1. true: return:`create` `campaign` -> `update` `BulletinDetail`

## Ongoing Chron Job

`chron_job`
01. get date two weeks in the past
02. `function_batch`(update: `true`) that

## 